<!DOCTYPE html>
<html>
<head>
<link rel="stylesheet" href="index.css">
</head>
    <body>

    <div id='navBar'>
        <ul id='leftNav'>
            <li><a href="index.html">TCAB</a></li>
        </ul>

        <ul id='rightNav'>
            <li class='active'><a href="index.html">Home</a></li>
            <li><a href="leaderboard.html">Leaderboard</a></li>
            <li><a href="index.html">Datasheet</a></li>
            <li><a href="index.html">Download</a></li>
            <li><a href="https://github.com/REACT-NLP">Github</a></li>
        </ul>
    </div>

    <div id='splashDiv'>
        <h1 id='splashTitle'>TCAB</h1>
        <h7 id='splashSubtitle'>The Text Classification Attack Benchmark</h7>
    </div>

    <div id='mainDiv'>
        <h3 class='subsectionHeader'>What is TCAB?</h3><hr>
        <p>
            TCAB is a set of benchmark datasets for analyzing, understanding, detecting, and labeling adversarial attacks against text classifiers. TCAB includes over 1.5 million successful attack instances, generated by twelve adversarial attacks targeting three classifiers trained on six source datasets for sentiment analysis and
            abuse detection in English.
        </p>
        <br>
        <h3 class='subsectionHeader'>Why was TCAB created?</h3><hr>
        <p>
            A common defense strategy against adversarial attacks is to make classifiers more robust, thus most evaluation frameworks focus on model robustness. However, these defenses are often computationally expensive or result in reduced accuracy. Additionally, benchmarks that evaluate these defenses require carefully controlled and expensive human filtering, typically resulting in a small number of evaluation examples.
        </p>
        <p>
            TCAB comprises a large collection of fully-automated attacks, enabling new tasks such as attack labeling --- automatically determining the adversarial attacks (if any) used to generate a given piece of text --- attack localization, and attack characterization. As a complement to model robustness, TCAB facilitates research that enables one to learn more about their attackers and subsequently develop appropriate defenses.
        </p>
        <h3 class='subsectionHeader'>Why was TCAB created?</h3><hr>
        <p>
            A common defense strategy against adversarial attacks is to make classifiers more robust, thus most evaluation frameworks focus on model robustness. However, these defenses are often computationally expensive or result in reduced accuracy. Additionally, benchmarks that evaluate these defenses require carefully controlled and expensive human filtering, typically resulting in a small number of evaluation examples.
        </p>
        <p>
            TCAB comprises a large collection of fully-automated attacks, enabling new tasks such as attack labeling --- automatically determining the adversarial attacks (if any) used to generate a given piece of text --- attack localization, and attack characterization. As a complement to model robustness, TCAB facilitates research that enables one to learn more about their attackers and subsequently develop appropriate defenses.
        </p>
    </div>

    <script type="text/javascript"></script>
</body>
</html>